{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d4e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8918bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create local streaming context with two working threads and batch interval of one second\n",
    "sc = SparkContext(\"local[2]\",\"NetworkWordCount\")\n",
    "ssc = StreamingContext(sc,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c592d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DStream that will connect to hostname:port like localhost:9999\n",
    "lines = ssc.socketTextStream(\"localhost\",9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11ff792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each line into words\n",
    "words = lines.flatMap(lambda line:line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69eee1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count each word in each batch\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# print the first 10 elements of each RDD generated into the conole\n",
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2007d3bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o25.awaitTermination.\n: java.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(Unknown Source)\r\n\tat java.net.SocketInputStream.read(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.readBytes(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.implRead(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.read(Unknown Source)\r\n\tat java.io.InputStreamReader.read(Unknown Source)\r\n\tat java.io.BufferedReader.fill(Unknown Source)\r\n\tat java.io.BufferedReader.readLine(Unknown Source)\r\n\tat java.io.BufferedReader.readLine(Unknown Source)\r\n\tat py4j.ClientServerConnection.readBlockingResponse(ClientServerConnection.java:313)\r\n\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:229)\r\n\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\r\n\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\r\n\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\r\n\tat com.sun.proxy.$Proxy32.call(Unknown Source)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\r\n\tat org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$3(DStream.scala:343)\r\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$2(DStream.scala:343)\r\n\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$1(DStream.scala:342)\r\n\tat scala.Option.orElse(Option.scala:447)\r\n\tat org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:335)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)\r\n\tat org.apache.spark.streaming.DStreamGraph.$anonfun$generateJobs$2(DStreamGraph.scala:123)\r\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\r\n\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\r\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\r\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\r\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\r\n\tat org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:122)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.$anonfun$generateJobs$1(JobGenerator.scala:254)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:252)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:186)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m ssc\u001b[38;5;241m.\u001b[39mstart() \u001b[38;5;66;03m# start the computation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\context.py:199\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mWait for the execution to stop.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    time to wait in seconds\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jssc\u001b[38;5;241m.\u001b[39mawaitTerminationOrTimeout(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.awaitTermination.\n: java.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(Unknown Source)\r\n\tat java.net.SocketInputStream.read(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.readBytes(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.implRead(Unknown Source)\r\n\tat sun.nio.cs.StreamDecoder.read(Unknown Source)\r\n\tat java.io.InputStreamReader.read(Unknown Source)\r\n\tat java.io.BufferedReader.fill(Unknown Source)\r\n\tat java.io.BufferedReader.readLine(Unknown Source)\r\n\tat java.io.BufferedReader.readLine(Unknown Source)\r\n\tat py4j.ClientServerConnection.readBlockingResponse(ClientServerConnection.java:313)\r\n\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:229)\r\n\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\r\n\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\r\n\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\r\n\tat com.sun.proxy.$Proxy32.call(Unknown Source)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\r\n\tat org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$3(DStream.scala:343)\r\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$2(DStream.scala:343)\r\n\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$getOrCompute$1(DStream.scala:342)\r\n\tat scala.Option.orElse(Option.scala:447)\r\n\tat org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:335)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)\r\n\tat org.apache.spark.streaming.DStreamGraph.$anonfun$generateJobs$2(DStreamGraph.scala:123)\r\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\r\n\tat scala.collection.mutable.ArraySeq.foreach(ArraySeq.scala:75)\r\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\r\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\r\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\r\n\tat org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:122)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.$anonfun$generateJobs$1(JobGenerator.scala:254)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:252)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:186)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:91)\r\n\tat org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:90)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n"
     ]
    }
   ],
   "source": [
    "ssc.start() # start the computation\n",
    "ssc.awaitTermination() # wait for the computation to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f314a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa5944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2c62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a948b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
